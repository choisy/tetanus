---
title: "Processing tetanus ELISA data"
number-sections: true
format:
  html:
    toc: true
editor: source
editor_options: 
  chunk_output_type: console
#bibliography: references.bib
#csl: the-american-naturalist.csl
---

```{r include = FALSE}
par2 <- function(...) par(..., mgp = c(1.5, .5, 0), bty = "n")

knitr::knit_hooks$set(
  margin1 = function(before, options, envir) {
    if (before) par2(plt = c(.105, .97, .15, .95)) else NULL
  })

eps <- .8
knitr::opts_chunk$set(margin1    = TRUE,
                      fig.retina = 2,
                      fig.align  = "center",
                      fig.height = eps * 5, # default is 5
                      fig.width  = eps * 7) # default is 7
```

## Parameters

The concentration of the reference anti-toxin is 10 IU/mL:

```{r}
ref_conc <- 10
```

The path to the data:

```{r}
path2data <- paste0(Sys.getenv("HOME"), "/Library/CloudStorage/",
                    "OneDrive-OxfordUniversityClinicalResearchUnit/",
                    "GitHub/choisy/tetanus/")
```

The name of the data file:

```{r include = FALSE}
make_path2 <- function(x) paste0(path2data, "cache/", x)
file_exists <- function(x) file.exists(make_path2(x))
readRDS3 <- function(x) readRDS(make_path2(x))
saveRDS2 <- function(object, file) saveRDS(object, make_path2(file))
```

```{r}
datafile <- "Tetanus_Dr. Thinh_HCDC samples.xlsx"
```


## Packages

Required packages:

```{r}
required_packages <- c("dplyr", "tibble", "readxl", "purrr", "mvtnorm")
```

Installing those that are not installed:

```{r}
to_inst <- required_packages[! required_packages %in% installed.packages()[,"Package"]]
if (length(to_inst)) install.packages(to_inst)
```

Loading some for interactive use:

```{r message = FALSE}
library(dplyr)
library(purrr)
```

## General functions

Tuning some base functions:

```{r}
lwd_val <- 2
color_data <- 4
color_model <- 2

make_path <- function(file) paste0(path2data, file)
read_excel2 <- function(file, ...) readxl::read_excel(make_path(file), ...)
excel_sheets2 <- function(file) readxl::excel_sheets(make_path(file))
plot2 <- function(...) plot(..., col = color_data)
seq2 <- function(...) seq(..., le = 512)
plotl <- function(...) plot(..., type = "l", col = color_model, lwd = lwd_val)
points2 <- function(...) points(..., col = color_data, pch = 3, lwd = lwd_val)
lines2 <- function(...) lines(..., col = color_model, lwd = lwd_val)
print_all <- function(x) print(x, n = nrow(x))
approx2 <- function(...) approx(..., ties = "ordered")
polygon2 <- function(x, y1, y2, ...) {
  polygon(c(x, rev(x)), c(y1, rev(y2)), border = NA, ...)
}
```

A function that splits the rows of a dataframe into a list of dataframes:

```{r}
rowsplit <- function(df) split(df, 1:nrow(df))
```

## Preparing the data

A function that removes the plate slot(s) that do(es) not contain any data:

```{r}
remove_empty_plates <- function(x) x[map_lgl(x, ~ ! all(is.na(.x$RESULT)))]
```

A function that adds the sample ID whenever missing:

```{r}
add_sample_id <- function(x) {
  id <- x$HCDC_SAMPLE_ID
  
  x$HCDC_SAMPLE_ID <- grep("Anti", id, value = TRUE, invert = TRUE) |> 
    na.exclude() |> 
    unique() |> 
    rep(each = 3) |> 
    c(grep("Anti", id, value = TRUE))
  
  x
}
```

Reading and arranging the data:

```{r}
plates <- datafile |>
  excel_sheets2() |> 
  (\(.x) .x[grepl("Plate", .x)])() |> 
  (\(.x) setNames(map(.x, read_excel2, file = datafile), .x))() |> 
  map(~ setNames(.x, toupper(names(.x)))) |> 
  remove_empty_plates() |> 
  map(add_sample_id) |> 
  map(~ mutate(.x, od = RESULT - mean(c_across(starts_with("BLANK")))))
```

## Specific functions

A 4-parameter logistic model that relates optical density $\mbox{OD}$ to the logarithm
of the concentration $\mbox{LC}$:

$$
\mbox{OD} = d + \frac{a - d}{1 + e^{\left(\mbox{LC} - c\right)b}}
$$

where:

* $a$ is the minimum $\mbox{OD}$, *i.e.* when the concentration is $0$;
* $d$ is the maximum $\mbox{OD}$, *i.e.* when the concentration is $+\infty$;
* $c$ is the $\mbox{LC}$ of the point of inflexion, *i.e.* where $\mbox{OD} = (d - a) / 2$;
* $b$ is the Hill's slope of the curve, *i.e.* the slope of the curve at the inflexion point.

Two functions that implement the calibration of a 4PL model:

```{r}
good_guess4PL <- function(x, y, eps = 1) {
  nb_rep <- unique(table(x))
  the_order <- order(x)
  x <- x[the_order]
  y <- y[the_order]
  a <- min(y)
  d <- max(y)
  c <- approx2(y, x, (d - a) / 2)$y
  list(a = a,
       b = (approx2(x, y, c + eps)$y - approx2(x, y, c - eps)$y) / (2 * eps),
       c = c, d = d)
}

nls4PL <- function(df) {
  nls(od ~ d + (a - d) / (1 + exp((log(concentration) - c) * b)),
      df, with(df, good_guess4PL(log(concentration), od)))
}
```

A function that generate the standard curve with confidence interval in the form of a
dataframe:

```{r}
standard_curve_data <- function(df, model, le = 512, level = .95, nb = 9999) {
  fitted <- model(df)
  log_concentration <- log(df$concentration)
  logc <- seq(min(log_concentration), max(log_concentration), le = le)
  alpha <- (1 - level) / 2
  
  nb |>
    mvtnorm::rmvnorm(coef(fitted), vcov(fitted)) |> 
    as.data.frame() |>
    rowsplit() |> 
    map(as.list) |> 
    map(~ c(.x, concentration = list(exp(logc)))) |> 
    map_dfc(eval, expr = parse(text = as.character(formula(fitted))[3])) |> 
    apply(1, quantile, c(alpha, .5, 1 - alpha)) |>
    t() |> as.data.frame() |> 
    setNames(c("lower", "median", "upper")) |> 
    (\(.x) bind_cols(logc = logc, .x))()
}
```

```{r eval = FALSE, include = FALSE}
simulate_nls <- function(object, newdata, nb) {
  force(object)
  local_object <- object
  1:nb |> 
    map_dfc(function(i) {
          mvtnorm::rmvnorm(1, coef(local_object), vcov(local_object)) |> 
            as.data.frame() |> 
            as.vector() |> 
            unlist() |>
            local_object$m$setPars()
          predict(local_object, newdata)})
}
```

A function that plots the output of `standard_curve_data()` with or without data:

```{r}
plot_standard_curve <- function(scdf, data = NULL) {
  with(scdf, {
    plot(logc, scdf$lower, type = "n", ylim = c(0, max(upper, data$od)),
         xlab = "log(concentration)", ylab = "optical density")
    polygon2(logc, lower, upper, col = adjustcolor(color_model, .2))
    lines2(logc, median)
  })
  if (! is.null(data)) with(data, points2(log(concentration), od))
}
```

A function that converts a dataframe into a function:

```{r}
data2function <- function(df) {
  with(df, {
    make_pred_function <- function(data) function(x) approx(data, logc, x)$y
    pred_lwr <- make_pred_function(upper)
    pred_mdi <- make_pred_function(median)
    pred_upp <- make_pred_function(lower)
    function(x) c(lower = pred_lwr(x), median = pred_mdi(x), upper = pred_upp(x))
  })
}
```

A function that retrieves the anti-toxins data from a plate:

```{r}
get_antitoxins <- function(plate) {
  plate |>
    filter(HCDC_SAMPLE_ID == "Anti_toxin") |> 
    mutate(concentration = ref_conc / DILUTION_FACTORS)
}
```

A function that retrieves the samples data from a plate:

```{r}
process_samples <- function(plate, std_crv) {
  plate |> 
    filter(HCDC_SAMPLE_ID != "Anti_toxin") |> 
    rowwise() |> 
    mutate(logconcentration = list(std_crv(RESULT))) |> 
    tidyr::unnest_wider(logconcentration)
}
```

An example on the first plate:

```{r}
plate <- plates$Plate_01_hcdc
```

The 4 steps:

```{r}
# step 1: retrieve the anti-toxins data:
anti_toxins <- get_antitoxins(plate)
# step 2: generate the standard curve with CI in the form of a dataframe:
standard_curve_df <- standard_curve_data(anti_toxins, nls4PL)
# step 3: convert the standard curve dataframe into a standard curve function:
standard_curve <- data2function(standard_curve_df)
# step 4: convert the OD of the samples into log-concentrations:
samples <- process_samples(plate, standard_curve)
```

The plots of the standard curve, with and without data:

```{r}
plot_standard_curve(standard_curve_df)
plot_standard_curve(standard_curve_df, anti_toxins)
```


## Processing all the plates

```{r eval = FALSE}
anti_toxins <- map(plates, get_antitoxins)
standard_curve_df <- map(anti_toxins, standard_curve_data, nls4PL)
standard_curves <- map(standard_curve_df, data2function)
samples <- map2(plates, standard_curves, process_samples)
```

```{r include = FALSE}
anti_toxins <- map(plates, get_antitoxins)
if (file_exists("standard_curve_df.rds")) {
  standard_curve_df <- readRDS3("standard_curve_df.rds")
} else {
  standard_curve_df <- map(anti_toxins, standard_curve_data, nls4PL)
  saveRDS2(standard_curve_df, "standard_curve_df.rds")
}
standard_curves <- map(standard_curve_df, data2function)
samples <- map2(plates, standard_curves, process_samples)
```

```{r}
NA_locations <- function(x) {
  c(l   = nrow(filter(x,   is.na(lower), ! is.na(median), ! is.na(upper))),
    lm  = nrow(filter(x,   is.na(lower),   is.na(median), ! is.na(upper))),
    all = nrow(filter(x,   is.na(lower),   is.na(median),   is.na(upper))),
    um  = nrow(filter(x, ! is.na(lower),   is.na(median),   is.na(upper))),
    u   = nrow(filter(x, ! is.na(lower), ! is.na(median),   is.na(upper))))  
}
```

This suggests that the more diluted the samples, the better:

```{r}
map_dfr(samples, ~ .x |> NA_locations()) |> 
  print_all()
```

```{r}
ranges <- map_dfr(samples, ~ .x |>
                    filter(is.na(lower) | is.na(median) | is.na(upper)) |> 
                    pull(od) |>
                    range() |>
                    setNames(c("min", "max")))
print_all(ranges)
```

```{r}
threshold <- .31

samples[which(ranges$min < threshold)] |> 
  map(~ filter(.x,
               HCDC_SAMPLE_ID %in% pull(filter(.x, od < threshold), HCDC_SAMPLE_ID)) |> 
        select(HCDC_SAMPLE_ID, DILUTION_FACTORS, RESULT, od, lower, median, upper))
```




## Plots

```{r fig.width = 8, fig.height = 5.25, margin1 = FALSE, margin3 = TRUE}
# this is for a 3 x 3 plot
```
